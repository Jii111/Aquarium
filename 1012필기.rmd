<<1012>>
-트리의 노드는 x_j > t이므로, X_j, t를 찾아야 함
-fitted value : Y_1^bar(=sigma(R_1에 속하는 i)Yi/n_R1), Y_2^bar

-"Impurity" 최소화
-Reg에서 이 Measure = RSS
-RSS = sigma(R_1에 속하는 i)(Y_i-Y^bar)^2/n_R1 + sigma(R_2에 속하는 i)(Y_i-Y^bar)^2/n_R2

for eg.
X1=[1,3,9,15,25,30]
(x,0:6) X1<1
(1:5) X1<9
...
(5:1) X1<25
=> 이 중에 minimum 찾자

X1<15에서 RSS가 Min이 되면 X1의 Best splitting point 찾았음 => Rss_X1
X2 똑같은 작업 반복 => X2<30 Best RSS_X2
...
Xp 똑같은 작업 반복 => Xp<30 Best RSS_Xp
=> Best of Best?
예를 들어 RSS_X5 Min -> 첫번째 splitting variable point 찾았다

=> 각각의 child node에서 같은 작업 수행, 즉 Best split(=Min RSS) 찾는다

#데이터 수 커지만 시간 좀 오래 걸림

-언제까지 grow? When we stop?
: node에 속한 obs의 수 < predicted n_*, then stop, n_*=10 or 5
# tree는 missing value가 있어도 fitting 할 수 있음
# missing있는 경우 어떻게 처리하는지



```{r}
# Regression Tree fitting

algae <- read.table('C:/Users/user/Downloads/Analysis.txt',
             header=F,
             dec='.',
             col.names=c('season','size','speed','mxPH','mnO2','Cl','NO3',
             'NH4','oPO4','PO4','Chla','a1','a2','a3','a4','a5','a6','a7'),
             na.strings=c('XXXXXXX'))
algae <- algae[-c(62,199),]


algae$season<-as.factor(algae$season) # character로 뜨면 안되냐능???
# 봄여름가을겨울을 2개로 나눈다? 6개의 경우의 수
# season : bc
# levels(season)해서 나오는 결과 따라 fall(a), spirng(b)
algae$speed<-as.factor(algae$speed)
algae$size<-as.factor(algae$size)

library(tree)
tr1<-tree(a1~., data=algae[,1:12])
plot(tr1);text(tr1)
plot(algae$a1,predict(tr1,algae))
abline(0,1,col=2)
## check predicted values for the observations with missing
```

```{r}
tr1
```
<<root 184>> : missing 제외
<<75540.0>> : deviance, residual sum of square
<<15.320>>
```{r}
aa<-algae[complete.cases(algae),'a1']
length(aa)
mean(aa) ##15.320

sum((aa-mean(aa))^2)
```
2) Cl < 7.2915에맞는 게 27개 10120.0 46.380 
3) Cl > 7.2915 157 34890.0  9.975  
CI 값이 적을 수록 조류의 양이 많구나 알 수 있다

*가 붙은 건 마지막 노드라는 뜻

-언제까지?
tree.control(!,mincut = 5, mindev = 0.01) <=> 5개보다 작으면 split 하지뫄
```{r}

tr2<-tree(a1~.,data=algae[,1:12],mincut=20)
plot(tr2);text(tr2)
# 훨씬 간단해짐

tr3<-tree(a1~.,data=algae[,1:12],mincut=2)
plot(tr3);text(tr3)
```

-tree의 장점
0보다 작은 predict가 없다!
왜? fitted value는 이미 있는 y들의 평균이므로, 0보다 작은 y값이 없음, original y의 range를 벗어나지 않음 => 장점

```{r}

# regression 후에는 plot(observed vs fitted) 꼭 그려보기(1000% 시험 나옴)
plot(algae$a1,predict(tr1,algae))
abline(0,1,col=2)
# 계단식으로 plot이 나와야 가장 좋음(tree니까!)
# y: fitted, x: obseved

plot(algae$a1,predict(tr2,algae))
abline(0,1,col=2)
# missing value가 있어서(Cl, PO4에서 missing 있었음) 5개가 아님 .. 뭐가?(plot에서 가로로 보기)
algae[!complete.cases(algae),1:12]
# Cl missing인 애는 stop하고, 그냥 그 전 노드까지의 평균(15.3)이 예측 값이 됨

```

```{r}

# cv-error로 최적 모형 찾기
tr1.cv<-cv.tree(tr1) #보통 10fold 많이 사용
tr1.cv

plot(tr1.cv)
#size : terminal node의 개수
#tree의 복잡성은 terminal node의 개수가 결정
#deviance = residual sum of mean squared
# overfitting 되면서 cv-error값이 다시 커짐

#내 plot은 4에서 minimum, 교수님은 5에서 minimum : cv-error는 태생적으로 randomness가 존재하기 때문

tr1.cv<-cv.tree(tr1)
for (i in 2:10){
	tr1.cv$dev<-tr1.cv$dev+cv.tree(tr1)$dev
}
tr1.cv$dev<-tr1.cv$dev/10
plot(tr1.cv)  #find the best size
# error가 비슷할 땐 간단한 모형이 좋음

sim.n<-100
tr1.cv<-cv.tree(tr1)
for (i in 2:sim.n){
	tr1.cv$dev<-tr1.cv$dev+cv.tree(tr1)$dev
}
tr1.cv$dev<-tr1.cv$dev/sim.n
#plot(tr1.cv) #find the best size


final.tr<-prune.tree(tr1,best=4)
plot(final.tr);text(final.tr)
#이게 best 모형
# Cl은 역시 중요한 변수였다.
```

=> linear model이 좋은가 tree model이 좋은가? Use MSE
-Regression Performance Measure
  -MSE,RMSE
  -MSE = sigma(Y_i-Y_i^hat)^2/n
  -RMSE = sqrt(MSE)
  -MAE = sigma|Y_i-Y_i^hat)^2/n
  
  -nMSE(normalized) = {sigma(Y_i-Y_i^hat)^2/n}/{sigma(Y_i-Y^bar)^2/n} 
  #분모: 가장 간단한 모형일때의 예측 오차
  #이 값은 당연히 1보다 작아야 함, 1보다 크면? 뭘 굉장히 잘못했다
```{r}

algae <- read.table('C:/Users/user/Downloads/Analysis.txt',
             header=F,
             dec='.',
             col.names=c('season','size','speed','mxPH','mnO2','Cl','NO3',
             'NH4','oPO4','PO4','Chla','a1','a2','a3','a4','a5','a6','a7'),
             na.strings=c('XXXXXXX'))
algae <- algae[-c(62,199),] #remove observations with high missing rate
#recheck the categorical variables
algae$season<-as.factor(algae$season)
algae$speed<-as.factor(algae$speed)
algae$size<-as.factor(algae$size)

clean.algae <- algae
# 꼭 같은 데이터 사용!!

library(cluster)
dist.mtx <- as.matrix(daisy(algae[,1:11],stand=T))

central.value <- function(x) {
  if (is.numeric(x)) median(x,na.rm=T)
  else if (is.factor(x)) levels(x)[which.max(table(x))]
  else {
    f <- as.factor(x)
    levels(f)[which.max(table(f))]
  }
}


for(r in which(!complete.cases(algae))) clean.algae[r,which(is.na(algae[r,]))] <- apply(data.frame(algae[c(as.integer(names(sort(dist.mtx[r,])[2:11]))), which(is.na(algae[r,]))]), 2,central.value)
### Linear Model fitting 

lm.a1 <- lm(a1 ~ .,data=clean.algae[,1:12])

summary(lm.a1)

final.lm <- step(lm.a1) # linear model



```

```{r}

# 10000%의 확률로 물어봄
# 지금은 그냥 train data로 했음
# 값은 동일해야함
lm.predictions.a1 <- predict(final.lm,clean.algae)
rt.predictions.a1 <- predict(final.tr,algae)

(mae.a1.lm <- mean(abs(lm.predictions.a1-algae[,'a1'])))
(mae.a1.rt <- mean(abs(rt.predictions.a1-algae[,'a1'])))

(mse.a1.lm <- mean((lm.predictions.a1-algae[,'a1'])^2))
(mse.a1.rt <- mean((rt.predictions.a1-algae[,'a1'])^2))

(nmse.a1.lm <- mean((lm.predictions.a1-algae[,'a1'])^2)/mean((mean(algae[,'a1'])-algae[,'a1'])^2))
(nmse.a1.rt <- mean((rt.predictions.a1-algae[,'a1'])^2)/mean((mean(algae[,'a1'])-algae[,'a1'])^2))
# 결론 : tree 모형이 더 좋다. 값이 더 작으니까

```

```{r}

# plot
# 보통은 x가 true, y가 predict(->교재 코드 수정)
par(mfrow=c(1,2)) #plot space 나누기
plot(algae[,'a1'],lm.predictions.a1,main="Linear Model",ylab="Predictions",xlab="True Values")
abline(0,1,lty=2)
plot(algae[,'a1'],rt.predictions.a1,main="Regression Tree",ylab="Predictions",xlab="True Values")
abline(0,1,lty=2)

# 둘 다 예측력이 좋지않다는 걸 알 수 있음^^
# terminal 안에 있는 애들이 homogenious해야함 -> 값이 모여있어야 ideal

```

```{r}

sensible.lm.predictions.a1 <- ifelse(lm.predictions.a1 < 0,0,lm.predictions.a1)
(mae.a1.lm <- mean(abs(sensible.lm.predictions.a1-algae[,'a1'])))
(nmse.a1.lm <- mean((sensible.lm.predictions.a1-algae[,'a1'])^2)/mean((mean(algae[,'a1'])-algae[,'a1'])^2))
# 아즈 조금 작아짐

```
[중간 고사 공지]
-오늘 수업까지가 시험범위
-다음주는 summary 수업
-이론(train, test 왜 나눠야 하는가/tree란 뭔가)
-실제 데이터 주고 fitting(linear model, stepwise, 회귀 계수, 해석, categorical 변수 있는 경우, plot 등)
-자세한 이야기는 다음주 화요일에
